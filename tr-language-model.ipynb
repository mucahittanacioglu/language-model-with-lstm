{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./data/mevlana.txt\",\"r\",encoding=\"utf-8\")\n",
    "data=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering punctuations as word\n",
    "import string\n",
    "punct = \".,!?/’:\\\";\\-–“”'\"\n",
    "data = data.lower()\n",
    "data = data.replace(\"\\n\",\" \")\n",
    "tmp = \"\"\n",
    "\n",
    "for i in data:\n",
    "    if i.isalpha() or i == \" \":\n",
    "        tmp = tmp+i\n",
    "    elif i in punct:\n",
    "        tmp = tmp+\" \"+i+\" \"\n",
    "data = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 50000  # Number of words \n",
    "n_word = 5 # Number of word as input to model\n",
    "embedding_dim = 300 # Embedding vector dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_features,lower=False,filters=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = tokenizer.texts_to_sequences([data])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabluary size: 28960\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index)+1\n",
    "print(f\"Vocabluary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Input&Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(n_word, len(data_encoded)):\n",
    "    X.append(data_encoded[i-n_word:i])\n",
    "    y.append(data_encoded[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "X = np.array(X)\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained Turkish-GloVe embedding\n",
    "# source https://github.com/inzva/Turkish-GloVe\n",
    "embedding = open(\"embeddings/vectors.txt\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating embedding dictionary\n",
    "embedding_dict= {}\n",
    "for i in embedding:\n",
    "    line = i.split(' ')\n",
    "    line[-1]=line[-1].replace('\\n','')\n",
    "    embedding_dict[''+line[0]]=line[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253832"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = embedding_dict.keys()\n",
    "unk_token = np.zeros(300,)\n",
    "#Using unk_token(average of all vetors) for the words not in embedding ectors\n",
    "for i in keys:\n",
    "    unk_token = unk_token + np.array(embedding_dict[i],float)\n",
    "unk_token = unk_token / len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating embedding matrix\n",
    "counter = 0\n",
    "unk_words = []\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "embedding_matrix[0] = np.zeros(300,)\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i == vocab_size:\n",
    "        break\n",
    "    embedding_vector = embedding_dict.get(word)\n",
    "    if embedding_vector is  None:\n",
    "        #words not in embedding considered unk token\n",
    "        embedding_vector = unk_token.tolist()\n",
    "        counter = counter + 1\n",
    "        unk_words.append(word)\n",
    "    embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28960, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unk token usage: 7899\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unk token usage: {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['’',\n",
       " '“',\n",
       " '”',\n",
       " 'mecâlis',\n",
       " 'ıssı',\n",
       " '–',\n",
       " 'fîh',\n",
       " 'duacının',\n",
       " 'husâmeddin',\n",
       " 'barsîsa']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 5, 300)            8688000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 5, 128)            219648    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5, 256)            33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5, 128)            32896     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28960)             18563360  \n",
      "=================================================================\n",
      "Total params: 27,668,512\n",
      "Trainable params: 18,980,512\n",
      "Non-trainable params: 8,688,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,RNN,Dense,Embedding,Input,Flatten\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(5,)))\n",
    "model.add(Embedding(input_dim = vocab_size , weights =[embedding_matrix], output_dim = embedding_dim, input_length = n_word, trainable=False))\n",
    "model.add(LSTM(128,return_sequences = True))\n",
    "model.add(LSTM(128,return_sequences = True))\n",
    "model.add(Dense(256,activation = \"relu\"))\n",
    "model.add(Dense(128,activation = \"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile&Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call back for stop training at certein accuracy threshold\n",
    "from keras.callbacks import Callback\n",
    "class My_Callback(Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(My_Callback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        acc = logs[\"categorical_accuracy\"]\n",
    "        if acc >= self.threshold:\n",
    "            print(f\"Accuracy reach over {self.threshold}% terminating train process.\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "43/43 [==============================] - 41s 801ms/step - loss: 9.2970 - categorical_accuracy: 0.0438\n",
      "Epoch 2/500\n",
      "43/43 [==============================] - 28s 647ms/step - loss: 7.6196 - categorical_accuracy: 0.0871\n",
      "Epoch 3/500\n",
      "43/43 [==============================] - 25s 587ms/step - loss: 7.5447 - categorical_accuracy: 0.0876\n",
      "Epoch 4/500\n",
      "43/43 [==============================] - 25s 579ms/step - loss: 7.4958 - categorical_accuracy: 0.0870\n",
      "Epoch 5/500\n",
      "43/43 [==============================] - 25s 584ms/step - loss: 7.3555 - categorical_accuracy: 0.0891\n",
      "Epoch 6/500\n",
      "43/43 [==============================] - 25s 589ms/step - loss: 7.1404 - categorical_accuracy: 0.0924\n",
      "Epoch 7/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 6.8720 - categorical_accuracy: 0.1007\n",
      "Epoch 8/500\n",
      "43/43 [==============================] - 25s 589ms/step - loss: 6.5869 - categorical_accuracy: 0.1098\n",
      "Epoch 9/500\n",
      "43/43 [==============================] - 25s 590ms/step - loss: 6.3331 - categorical_accuracy: 0.1173\n",
      "Epoch 10/500\n",
      "43/43 [==============================] - 25s 593ms/step - loss: 6.0338 - categorical_accuracy: 0.1257\n",
      "Epoch 11/500\n",
      "43/43 [==============================] - 26s 595ms/step - loss: 5.7113 - categorical_accuracy: 0.1344\n",
      "Epoch 12/500\n",
      "43/43 [==============================] - 26s 599ms/step - loss: 5.3973 - categorical_accuracy: 0.1504\n",
      "Epoch 13/500\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 5.0683 - categorical_accuracy: 0.1816\n",
      "Epoch 14/500\n",
      "43/43 [==============================] - 26s 601ms/step - loss: 4.7706 - categorical_accuracy: 0.2172\n",
      "Epoch 15/500\n",
      "43/43 [==============================] - 26s 605ms/step - loss: 4.4533 - categorical_accuracy: 0.2515\n",
      "Epoch 16/500\n",
      "43/43 [==============================] - 26s 599ms/step - loss: 4.2029 - categorical_accuracy: 0.2768\n",
      "Epoch 17/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 3.9606 - categorical_accuracy: 0.3023\n",
      "Epoch 18/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 3.7789 - categorical_accuracy: 0.3211\n",
      "Epoch 19/500\n",
      "43/43 [==============================] - 26s 599ms/step - loss: 3.5817 - categorical_accuracy: 0.3444\n",
      "Epoch 20/500\n",
      "43/43 [==============================] - 26s 603ms/step - loss: 3.4058 - categorical_accuracy: 0.3658\n",
      "Epoch 21/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 3.2585 - categorical_accuracy: 0.3828\n",
      "Epoch 22/500\n",
      "43/43 [==============================] - 26s 593ms/step - loss: 3.1184 - categorical_accuracy: 0.4003\n",
      "Epoch 23/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 3.0052 - categorical_accuracy: 0.4134\n",
      "Epoch 24/500\n",
      "43/43 [==============================] - 26s 601ms/step - loss: 2.8838 - categorical_accuracy: 0.4282\n",
      "Epoch 25/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 2.7733 - categorical_accuracy: 0.4446\n",
      "Epoch 26/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 2.6763 - categorical_accuracy: 0.4582\n",
      "Epoch 27/500\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 2.5889 - categorical_accuracy: 0.4701\n",
      "Epoch 28/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 2.5108 - categorical_accuracy: 0.4791\n",
      "Epoch 29/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 2.4159 - categorical_accuracy: 0.4938\n",
      "Epoch 30/500\n",
      "43/43 [==============================] - 26s 599ms/step - loss: 2.3591 - categorical_accuracy: 0.5003\n",
      "Epoch 31/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 2.2706 - categorical_accuracy: 0.5162\n",
      "Epoch 32/500\n",
      "43/43 [==============================] - 26s 600ms/step - loss: 2.2352 - categorical_accuracy: 0.5192\n",
      "Epoch 33/500\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 2.1503 - categorical_accuracy: 0.5342\n",
      "Epoch 34/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 2.0961 - categorical_accuracy: 0.5418\n",
      "Epoch 35/500\n",
      "43/43 [==============================] - 26s 601ms/step - loss: 2.0467 - categorical_accuracy: 0.5482\n",
      "Epoch 36/500\n",
      "43/43 [==============================] - 26s 612ms/step - loss: 1.9994 - categorical_accuracy: 0.5569\n",
      "Epoch 37/500\n",
      "43/43 [==============================] - 26s 604ms/step - loss: 1.9565 - categorical_accuracy: 0.5634\n",
      "Epoch 38/500\n",
      "43/43 [==============================] - 26s 602ms/step - loss: 1.9105 - categorical_accuracy: 0.5720\n",
      "Epoch 39/500\n",
      "43/43 [==============================] - 26s 600ms/step - loss: 1.8667 - categorical_accuracy: 0.5774\n",
      "Epoch 40/500\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 1.8261 - categorical_accuracy: 0.5844\n",
      "Epoch 41/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 1.8003 - categorical_accuracy: 0.5892\n",
      "Epoch 42/500\n",
      "43/43 [==============================] - 25s 592ms/step - loss: 1.7613 - categorical_accuracy: 0.5960\n",
      "Epoch 43/500\n",
      "43/43 [==============================] - 25s 593ms/step - loss: 1.7270 - categorical_accuracy: 0.6030\n",
      "Epoch 44/500\n",
      "43/43 [==============================] - 26s 595ms/step - loss: 1.6944 - categorical_accuracy: 0.6071\n",
      "Epoch 45/500\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 1.6551 - categorical_accuracy: 0.6153\n",
      "Epoch 46/500\n",
      "43/43 [==============================] - 26s 593ms/step - loss: 1.6341 - categorical_accuracy: 0.6178\n",
      "Epoch 47/500\n",
      "43/43 [==============================] - 25s 593ms/step - loss: 1.6245 - categorical_accuracy: 0.6203\n",
      "Epoch 48/500\n",
      "43/43 [==============================] - 26s 593ms/step - loss: 1.5827 - categorical_accuracy: 0.6263\n",
      "Epoch 49/500\n",
      "43/43 [==============================] - 25s 593ms/step - loss: 1.5616 - categorical_accuracy: 0.6304\n",
      "Epoch 50/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 1.5291 - categorical_accuracy: 0.6358\n",
      "Epoch 51/500\n",
      "43/43 [==============================] - 26s 595ms/step - loss: 1.5096 - categorical_accuracy: 0.6410\n",
      "Epoch 52/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 1.4949 - categorical_accuracy: 0.6407\n",
      "Epoch 53/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 1.4689 - categorical_accuracy: 0.6473\n",
      "Epoch 54/500\n",
      "43/43 [==============================] - 25s 593ms/step - loss: 1.4527 - categorical_accuracy: 0.6504\n",
      "Epoch 55/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 1.4459 - categorical_accuracy: 0.6515\n",
      "Epoch 56/500\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 1.3981 - categorical_accuracy: 0.6591\n",
      "Epoch 57/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 1.3943 - categorical_accuracy: 0.6610\n",
      "Epoch 58/500\n",
      "43/43 [==============================] - 26s 595ms/step - loss: 1.3521 - categorical_accuracy: 0.6700\n",
      "Epoch 59/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 1.3480 - categorical_accuracy: 0.6702\n",
      "Epoch 60/500\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 1.3312 - categorical_accuracy: 0.6739\n",
      "Epoch 61/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 1.3245 - categorical_accuracy: 0.6755\n",
      "Epoch 62/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 1.3270 - categorical_accuracy: 0.6716\n",
      "Epoch 63/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 1.3022 - categorical_accuracy: 0.6774\n",
      "Epoch 64/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 1.2786 - categorical_accuracy: 0.6836\n",
      "Epoch 65/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 1.2636 - categorical_accuracy: 0.6861\n",
      "Epoch 66/500\n",
      "43/43 [==============================] - 26s 602ms/step - loss: 1.2353 - categorical_accuracy: 0.6914\n",
      "Epoch 67/500\n",
      "43/43 [==============================] - 26s 602ms/step - loss: 1.2215 - categorical_accuracy: 0.6937\n",
      "Epoch 68/500\n",
      "43/43 [==============================] - 26s 604ms/step - loss: 1.1976 - categorical_accuracy: 0.7013\n",
      "Epoch 69/500\n",
      "43/43 [==============================] - 25s 592ms/step - loss: 1.1979 - categorical_accuracy: 0.6984\n",
      "Epoch 70/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 1.1858 - categorical_accuracy: 0.7028\n",
      "Epoch 71/500\n",
      "43/43 [==============================] - 25s 589ms/step - loss: 1.1731 - categorical_accuracy: 0.7037\n",
      "Epoch 72/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 1.1537 - categorical_accuracy: 0.7072\n",
      "Epoch 73/500\n",
      "43/43 [==============================] - 26s 600ms/step - loss: 1.1413 - categorical_accuracy: 0.7111\n",
      "Epoch 74/500\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 1.1349 - categorical_accuracy: 0.7122\n",
      "Epoch 75/500\n",
      "43/43 [==============================] - 26s 599ms/step - loss: 1.1196 - categorical_accuracy: 0.7153\n",
      "Epoch 76/500\n",
      "43/43 [==============================] - 26s 599ms/step - loss: 1.1087 - categorical_accuracy: 0.7181\n",
      "Epoch 77/500\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 1.0971 - categorical_accuracy: 0.7193\n",
      "Epoch 78/500\n",
      "43/43 [==============================] - 26s 609ms/step - loss: 1.0903 - categorical_accuracy: 0.7216\n",
      "Epoch 79/500\n",
      "43/43 [==============================] - 26s 608ms/step - loss: 1.0846 - categorical_accuracy: 0.7210\n",
      "Epoch 80/500\n",
      "43/43 [==============================] - 26s 607ms/step - loss: 1.0641 - categorical_accuracy: 0.7261\n",
      "Epoch 81/500\n",
      "43/43 [==============================] - 26s 612ms/step - loss: 1.0528 - categorical_accuracy: 0.7297\n",
      "Epoch 82/500\n",
      "43/43 [==============================] - 26s 601ms/step - loss: 1.0386 - categorical_accuracy: 0.7308\n",
      "Epoch 83/500\n",
      "43/43 [==============================] - 26s 611ms/step - loss: 1.0413 - categorical_accuracy: 0.7305\n",
      "Epoch 84/500\n",
      "43/43 [==============================] - 25s 584ms/step - loss: 1.0307 - categorical_accuracy: 0.7344\n",
      "Epoch 85/500\n",
      "43/43 [==============================] - 25s 580ms/step - loss: 1.0111 - categorical_accuracy: 0.7369\n",
      "Epoch 86/500\n",
      "43/43 [==============================] - 25s 584ms/step - loss: 0.9976 - categorical_accuracy: 0.7388\n",
      "Epoch 87/500\n",
      "43/43 [==============================] - 25s 585ms/step - loss: 0.9908 - categorical_accuracy: 0.7413\n",
      "Epoch 88/500\n",
      "43/43 [==============================] - 25s 584ms/step - loss: 0.9723 - categorical_accuracy: 0.7456\n",
      "Epoch 89/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 0.9651 - categorical_accuracy: 0.7478\n",
      "Epoch 90/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 0.9660 - categorical_accuracy: 0.7476\n",
      "Epoch 91/500\n",
      "43/43 [==============================] - 25s 587ms/step - loss: 0.9493 - categorical_accuracy: 0.7524\n",
      "Epoch 92/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 0.9353 - categorical_accuracy: 0.7530\n",
      "Epoch 93/500\n",
      "43/43 [==============================] - 25s 586ms/step - loss: 0.9456 - categorical_accuracy: 0.7501\n",
      "Epoch 94/500\n",
      "43/43 [==============================] - 25s 581ms/step - loss: 0.9278 - categorical_accuracy: 0.7542\n",
      "Epoch 95/500\n",
      "43/43 [==============================] - 25s 586ms/step - loss: 0.9097 - categorical_accuracy: 0.7588\n",
      "Epoch 96/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 0.9022 - categorical_accuracy: 0.7615\n",
      "Epoch 97/500\n",
      "43/43 [==============================] - 25s 583ms/step - loss: 0.8982 - categorical_accuracy: 0.7611\n",
      "Epoch 98/500\n",
      "43/43 [==============================] - 25s 586ms/step - loss: 0.9021 - categorical_accuracy: 0.7594\n",
      "Epoch 99/500\n",
      "43/43 [==============================] - 25s 587ms/step - loss: 0.8772 - categorical_accuracy: 0.7679\n",
      "Epoch 100/500\n",
      "43/43 [==============================] - 25s 585ms/step - loss: 0.8659 - categorical_accuracy: 0.7685\n",
      "Epoch 101/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 0.8520 - categorical_accuracy: 0.7729\n",
      "Epoch 102/500\n",
      "43/43 [==============================] - 26s 600ms/step - loss: 0.8507 - categorical_accuracy: 0.7724\n",
      "Epoch 103/500\n",
      "43/43 [==============================] - 26s 601ms/step - loss: 0.8428 - categorical_accuracy: 0.7733\n",
      "Epoch 104/500\n",
      "43/43 [==============================] - 25s 581ms/step - loss: 0.8394 - categorical_accuracy: 0.7747\n",
      "Epoch 105/500\n",
      "43/43 [==============================] - 25s 586ms/step - loss: 0.8355 - categorical_accuracy: 0.7750\n",
      "Epoch 106/500\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 0.8243 - categorical_accuracy: 0.7780\n",
      "Epoch 107/500\n",
      "43/43 [==============================] - 25s 589ms/step - loss: 0.8217 - categorical_accuracy: 0.7791\n",
      "Epoch 108/500\n",
      "43/43 [==============================] - 26s 606ms/step - loss: 0.8214 - categorical_accuracy: 0.7782\n",
      "Epoch 109/500\n",
      "43/43 [==============================] - 26s 609ms/step - loss: 0.7972 - categorical_accuracy: 0.7846\n",
      "Epoch 110/500\n",
      "43/43 [==============================] - 26s 603ms/step - loss: 0.7962 - categorical_accuracy: 0.7853\n",
      "Epoch 111/500\n",
      "43/43 [==============================] - 26s 601ms/step - loss: 0.7973 - categorical_accuracy: 0.7836\n",
      "Epoch 112/500\n",
      "43/43 [==============================] - 25s 583ms/step - loss: 0.7723 - categorical_accuracy: 0.7916\n",
      "Epoch 113/500\n",
      "43/43 [==============================] - 25s 585ms/step - loss: 0.7551 - categorical_accuracy: 0.7954\n",
      "Epoch 114/500\n",
      "43/43 [==============================] - 27s 619ms/step - loss: 0.7776 - categorical_accuracy: 0.7878\n",
      "Epoch 115/500\n",
      "43/43 [==============================] - 27s 619ms/step - loss: 0.7602 - categorical_accuracy: 0.7938\n",
      "Epoch 116/500\n",
      "43/43 [==============================] - 27s 619ms/step - loss: 0.7426 - categorical_accuracy: 0.7965\n",
      "Epoch 117/500\n",
      "43/43 [==============================] - 27s 616ms/step - loss: 0.7557 - categorical_accuracy: 0.7934\n",
      "Epoch 118/500\n",
      "43/43 [==============================] - 27s 622ms/step - loss: 0.7283 - categorical_accuracy: 0.8018\n",
      "Epoch 119/500\n",
      "43/43 [==============================] - 27s 630ms/step - loss: 0.7381 - categorical_accuracy: 0.7979\n",
      "Epoch 120/500\n",
      "43/43 [==============================] - 27s 630ms/step - loss: 0.7215 - categorical_accuracy: 0.8023\n",
      "Epoch 121/500\n",
      "43/43 [==============================] - 26s 616ms/step - loss: 0.7210 - categorical_accuracy: 0.8030\n",
      "Epoch 122/500\n",
      "43/43 [==============================] - 26s 616ms/step - loss: 0.7063 - categorical_accuracy: 0.8069\n",
      "Epoch 123/500\n",
      "43/43 [==============================] - 27s 627ms/step - loss: 0.7064 - categorical_accuracy: 0.8055\n",
      "Epoch 124/500\n",
      "43/43 [==============================] - 27s 628ms/step - loss: 0.6984 - categorical_accuracy: 0.8073\n",
      "Epoch 125/500\n",
      "43/43 [==============================] - 27s 625ms/step - loss: 0.6877 - categorical_accuracy: 0.8122\n",
      "Epoch 126/500\n",
      "43/43 [==============================] - 27s 625ms/step - loss: 0.6820 - categorical_accuracy: 0.8143\n",
      "Epoch 127/500\n",
      "43/43 [==============================] - 27s 621ms/step - loss: 0.6772 - categorical_accuracy: 0.8146\n",
      "Epoch 128/500\n",
      "43/43 [==============================] - 27s 635ms/step - loss: 0.6772 - categorical_accuracy: 0.8139\n",
      "Epoch 129/500\n",
      "43/43 [==============================] - 27s 624ms/step - loss: 0.6712 - categorical_accuracy: 0.8152\n",
      "Epoch 130/500\n",
      "43/43 [==============================] - 27s 634ms/step - loss: 0.6557 - categorical_accuracy: 0.8200\n",
      "Epoch 131/500\n",
      "43/43 [==============================] - 27s 625ms/step - loss: 0.6515 - categorical_accuracy: 0.8212\n",
      "Epoch 132/500\n",
      "43/43 [==============================] - 27s 626ms/step - loss: 0.6464 - categorical_accuracy: 0.8216\n",
      "Epoch 133/500\n",
      "43/43 [==============================] - 27s 634ms/step - loss: 0.6494 - categorical_accuracy: 0.8192\n",
      "Epoch 134/500\n",
      "43/43 [==============================] - 26s 612ms/step - loss: 0.6433 - categorical_accuracy: 0.8208\n",
      "Epoch 135/500\n",
      "43/43 [==============================] - 25s 582ms/step - loss: 0.6363 - categorical_accuracy: 0.8249\n",
      "Epoch 136/500\n",
      "43/43 [==============================] - 26s 608ms/step - loss: 0.6339 - categorical_accuracy: 0.8240\n",
      "Epoch 137/500\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 0.6352 - categorical_accuracy: 0.8231\n",
      "Epoch 138/500\n",
      "43/43 [==============================] - 25s 589ms/step - loss: 0.6122 - categorical_accuracy: 0.8308\n",
      "Epoch 139/500\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 0.6025 - categorical_accuracy: 0.8315\n",
      "Epoch 140/500\n",
      "43/43 [==============================] - 25s 587ms/step - loss: 0.6129 - categorical_accuracy: 0.8296\n",
      "Epoch 141/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 0.6048 - categorical_accuracy: 0.8311\n",
      "Epoch 142/500\n",
      "43/43 [==============================] - 25s 585ms/step - loss: 0.5911 - categorical_accuracy: 0.8374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/500\n",
      "43/43 [==============================] - 26s 592ms/step - loss: 0.5836 - categorical_accuracy: 0.8371\n",
      "Epoch 144/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 0.5776 - categorical_accuracy: 0.8381\n",
      "Epoch 145/500\n",
      "43/43 [==============================] - 25s 587ms/step - loss: 0.5646 - categorical_accuracy: 0.8435\n",
      "Epoch 146/500\n",
      "43/43 [==============================] - 25s 584ms/step - loss: 0.5722 - categorical_accuracy: 0.8425\n",
      "Epoch 147/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 0.5630 - categorical_accuracy: 0.8432\n",
      "Epoch 148/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 0.5561 - categorical_accuracy: 0.8449\n",
      "Epoch 149/500\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 0.5427 - categorical_accuracy: 0.8502\n",
      "Epoch 150/500\n",
      "43/43 [==============================] - 26s 600ms/step - loss: 0.5540 - categorical_accuracy: 0.8452\n",
      "Epoch 151/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 0.5414 - categorical_accuracy: 0.8482\n",
      "Epoch 152/500\n",
      "43/43 [==============================] - 26s 595ms/step - loss: 0.5239 - categorical_accuracy: 0.8556\n",
      "Epoch 153/500\n",
      "43/43 [==============================] - 26s 593ms/step - loss: 0.5482 - categorical_accuracy: 0.8454\n",
      "Epoch 154/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 0.5305 - categorical_accuracy: 0.8524\n",
      "Epoch 155/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 0.5096 - categorical_accuracy: 0.8588\n",
      "Epoch 156/500\n",
      "43/43 [==============================] - 26s 599ms/step - loss: 0.5152 - categorical_accuracy: 0.8557\n",
      "Epoch 157/500\n",
      "43/43 [==============================] - 26s 603ms/step - loss: 0.5089 - categorical_accuracy: 0.8583\n",
      "Epoch 158/500\n",
      "43/43 [==============================] - 25s 589ms/step - loss: 0.5087 - categorical_accuracy: 0.8568\n",
      "Epoch 159/500\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 0.4836 - categorical_accuracy: 0.8654\n",
      "Epoch 160/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 0.4944 - categorical_accuracy: 0.8623\n",
      "Epoch 161/500\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 0.4908 - categorical_accuracy: 0.8648\n",
      "Epoch 162/500\n",
      "43/43 [==============================] - 25s 590ms/step - loss: 0.4892 - categorical_accuracy: 0.8637\n",
      "Epoch 163/500\n",
      "43/43 [==============================] - 26s 600ms/step - loss: 0.4760 - categorical_accuracy: 0.8687\n",
      "Epoch 164/500\n",
      "43/43 [==============================] - 26s 608ms/step - loss: 0.4697 - categorical_accuracy: 0.8685\n",
      "Epoch 165/500\n",
      "43/43 [==============================] - 26s 602ms/step - loss: 0.4732 - categorical_accuracy: 0.8672\n",
      "Epoch 166/500\n",
      "43/43 [==============================] - 26s 601ms/step - loss: 0.4760 - categorical_accuracy: 0.8662\n",
      "Epoch 167/500\n",
      "43/43 [==============================] - 26s 593ms/step - loss: 0.4741 - categorical_accuracy: 0.8674\n",
      "Epoch 168/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 0.4558 - categorical_accuracy: 0.8721\n",
      "Epoch 169/500\n",
      "43/43 [==============================] - 26s 602ms/step - loss: 0.4547 - categorical_accuracy: 0.8724\n",
      "Epoch 170/500\n",
      "43/43 [==============================] - 26s 592ms/step - loss: 0.4554 - categorical_accuracy: 0.8728\n",
      "Epoch 171/500\n",
      "43/43 [==============================] - 25s 593ms/step - loss: 0.4538 - categorical_accuracy: 0.8736\n",
      "Epoch 172/500\n",
      "43/43 [==============================] - 26s 600ms/step - loss: 0.4363 - categorical_accuracy: 0.8787\n",
      "Epoch 173/500\n",
      "43/43 [==============================] - 26s 603ms/step - loss: 0.4179 - categorical_accuracy: 0.8847\n",
      "Epoch 174/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 0.4274 - categorical_accuracy: 0.8800\n",
      "Epoch 175/500\n",
      "43/43 [==============================] - 25s 587ms/step - loss: 0.4422 - categorical_accuracy: 0.8750\n",
      "Epoch 176/500\n",
      "43/43 [==============================] - 25s 587ms/step - loss: 0.4284 - categorical_accuracy: 0.8812\n",
      "Epoch 177/500\n",
      "43/43 [==============================] - 25s 590ms/step - loss: 0.4188 - categorical_accuracy: 0.8844\n",
      "Epoch 178/500\n",
      "43/43 [==============================] - 26s 600ms/step - loss: 0.3965 - categorical_accuracy: 0.8914\n",
      "Epoch 179/500\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 0.4006 - categorical_accuracy: 0.8885\n",
      "Epoch 180/500\n",
      "43/43 [==============================] - 26s 604ms/step - loss: 0.4075 - categorical_accuracy: 0.8865\n",
      "Epoch 181/500\n",
      "43/43 [==============================] - 26s 607ms/step - loss: 0.4259 - categorical_accuracy: 0.8803\n",
      "Epoch 182/500\n",
      "43/43 [==============================] - 26s 603ms/step - loss: 0.4113 - categorical_accuracy: 0.8836\n",
      "Epoch 183/500\n",
      "43/43 [==============================] - 26s 601ms/step - loss: 0.3949 - categorical_accuracy: 0.8896\n",
      "Epoch 184/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 0.4090 - categorical_accuracy: 0.8849\n",
      "Epoch 185/500\n",
      "43/43 [==============================] - 25s 590ms/step - loss: 0.3896 - categorical_accuracy: 0.8893\n",
      "Epoch 186/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 0.4220 - categorical_accuracy: 0.8792\n",
      "Epoch 187/500\n",
      "43/43 [==============================] - 25s 592ms/step - loss: 0.3963 - categorical_accuracy: 0.8883\n",
      "Epoch 188/500\n",
      "43/43 [==============================] - 26s 600ms/step - loss: 0.3864 - categorical_accuracy: 0.8923\n",
      "Epoch 189/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 0.3741 - categorical_accuracy: 0.8960\n",
      "Epoch 190/500\n",
      "43/43 [==============================] - 26s 604ms/step - loss: 0.3662 - categorical_accuracy: 0.8989\n",
      "Epoch 191/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 0.3650 - categorical_accuracy: 0.9005\n",
      "Epoch 192/500\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 0.3728 - categorical_accuracy: 0.8960\n",
      "Epoch 193/500\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 0.3784 - categorical_accuracy: 0.8935\n",
      "Epoch 194/500\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 0.3524 - categorical_accuracy: 0.9033\n",
      "Epoch 195/500\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 0.3490 - categorical_accuracy: 0.9033\n",
      "Epoch 196/500\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 0.3378 - categorical_accuracy: 0.9090\n",
      "Epoch 197/500\n",
      "43/43 [==============================] - 25s 586ms/step - loss: 0.3384 - categorical_accuracy: 0.9070\n",
      "Epoch 198/500\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 0.3306 - categorical_accuracy: 0.9101\n",
      "Epoch 199/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 0.3180 - categorical_accuracy: 0.9139\n",
      "Epoch 200/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 0.3245 - categorical_accuracy: 0.9098\n",
      "Epoch 201/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 0.3514 - categorical_accuracy: 0.8999\n",
      "Epoch 202/500\n",
      "43/43 [==============================] - 25s 585ms/step - loss: 0.3267 - categorical_accuracy: 0.9102\n",
      "Epoch 203/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 0.3168 - categorical_accuracy: 0.9136\n",
      "Epoch 204/500\n",
      "43/43 [==============================] - 25s 589ms/step - loss: 0.3166 - categorical_accuracy: 0.9128\n",
      "Epoch 205/500\n",
      "43/43 [==============================] - 25s 587ms/step - loss: 0.3064 - categorical_accuracy: 0.9159\n",
      "Epoch 206/500\n",
      "43/43 [==============================] - 25s 592ms/step - loss: 0.3064 - categorical_accuracy: 0.9153\n",
      "Epoch 207/500\n",
      "43/43 [==============================] - 26s 595ms/step - loss: 0.2923 - categorical_accuracy: 0.9218\n",
      "Epoch 208/500\n",
      "43/43 [==============================] - 25s 586ms/step - loss: 0.2917 - categorical_accuracy: 0.9209\n",
      "Epoch 209/500\n",
      "43/43 [==============================] - 25s 581ms/step - loss: 0.2944 - categorical_accuracy: 0.9195\n",
      "Epoch 210/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 0.2861 - categorical_accuracy: 0.9227\n",
      "Epoch 211/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 0.2891 - categorical_accuracy: 0.9211\n",
      "Epoch 212/500\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 0.2941 - categorical_accuracy: 0.9192\n",
      "Epoch 213/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 0.2908 - categorical_accuracy: 0.9198\n",
      "Epoch 214/500\n",
      "43/43 [==============================] - 25s 585ms/step - loss: 0.3208 - categorical_accuracy: 0.9094\n",
      "Epoch 215/500\n",
      "43/43 [==============================] - 25s 590ms/step - loss: 0.2845 - categorical_accuracy: 0.9223\n",
      "Epoch 216/500\n",
      "43/43 [==============================] - 26s 603ms/step - loss: 0.2945 - categorical_accuracy: 0.9181\n",
      "Epoch 217/500\n",
      "43/43 [==============================] - 26s 610ms/step - loss: 0.2954 - categorical_accuracy: 0.9194\n",
      "Epoch 218/500\n",
      "43/43 [==============================] - 26s 601ms/step - loss: 0.2745 - categorical_accuracy: 0.9245\n",
      "Epoch 219/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 0.2720 - categorical_accuracy: 0.9265\n",
      "Epoch 220/500\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 0.2631 - categorical_accuracy: 0.9288\n",
      "Epoch 221/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 0.2874 - categorical_accuracy: 0.9215\n",
      "Epoch 222/500\n",
      "43/43 [==============================] - 25s 581ms/step - loss: 0.2737 - categorical_accuracy: 0.9251\n",
      "Epoch 223/500\n",
      "43/43 [==============================] - 25s 586ms/step - loss: 0.2622 - categorical_accuracy: 0.9273\n",
      "Epoch 224/500\n",
      "43/43 [==============================] - 25s 592ms/step - loss: 0.2623 - categorical_accuracy: 0.9282\n",
      "Epoch 225/500\n",
      "43/43 [==============================] - 26s 600ms/step - loss: 0.2689 - categorical_accuracy: 0.9260\n",
      "Epoch 226/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 0.2534 - categorical_accuracy: 0.9310\n",
      "Epoch 227/500\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 0.2770 - categorical_accuracy: 0.9219\n",
      "Epoch 228/500\n",
      "43/43 [==============================] - 25s 589ms/step - loss: 0.2829 - categorical_accuracy: 0.9187\n",
      "Epoch 229/500\n",
      "43/43 [==============================] - 25s 592ms/step - loss: 0.2581 - categorical_accuracy: 0.9289\n",
      "Epoch 230/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 0.2490 - categorical_accuracy: 0.9316\n",
      "Epoch 231/500\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 0.2379 - categorical_accuracy: 0.9362\n",
      "Epoch 232/500\n",
      "43/43 [==============================] - 25s 593ms/step - loss: 0.2287 - categorical_accuracy: 0.9404\n",
      "Epoch 233/500\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 0.2378 - categorical_accuracy: 0.9346\n",
      "Epoch 234/500\n",
      "43/43 [==============================] - 25s 592ms/step - loss: 0.2374 - categorical_accuracy: 0.9363\n",
      "Epoch 235/500\n",
      "43/43 [==============================] - 26s 600ms/step - loss: 0.2281 - categorical_accuracy: 0.9393\n",
      "Epoch 236/500\n",
      "43/43 [==============================] - 26s 603ms/step - loss: 0.2171 - categorical_accuracy: 0.9438\n",
      "Epoch 237/500\n",
      "43/43 [==============================] - 26s 601ms/step - loss: 0.2151 - categorical_accuracy: 0.9444\n",
      "Epoch 238/500\n",
      "43/43 [==============================] - 26s 606ms/step - loss: 0.2047 - categorical_accuracy: 0.9479\n",
      "Epoch 239/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 0.1990 - categorical_accuracy: 0.9498\n",
      "Epoch 240/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 0.1981 - categorical_accuracy: 0.9496\n",
      "Epoch 241/500\n",
      "43/43 [==============================] - 25s 588ms/step - loss: 0.2058 - categorical_accuracy: 0.9466\n",
      "Epoch 242/500\n",
      "43/43 [==============================] - 26s 595ms/step - loss: 0.2054 - categorical_accuracy: 0.9457\n",
      "Epoch 243/500\n",
      "43/43 [==============================] - 26s 595ms/step - loss: 0.2187 - categorical_accuracy: 0.9415\n",
      "Epoch 244/500\n",
      "43/43 [==============================] - 26s 600ms/step - loss: 0.2366 - categorical_accuracy: 0.9339\n",
      "Epoch 245/500\n",
      "43/43 [==============================] - 26s 604ms/step - loss: 0.2306 - categorical_accuracy: 0.9372\n",
      "Epoch 246/500\n",
      "43/43 [==============================] - 25s 589ms/step - loss: 0.2249 - categorical_accuracy: 0.9387\n",
      "Epoch 247/500\n",
      "43/43 [==============================] - 26s 602ms/step - loss: 0.2217 - categorical_accuracy: 0.9409\n",
      "Epoch 248/500\n",
      "43/43 [==============================] - 26s 600ms/step - loss: 0.2235 - categorical_accuracy: 0.9394\n",
      "Epoch 249/500\n",
      "43/43 [==============================] - 26s 592ms/step - loss: 0.2397 - categorical_accuracy: 0.9322\n",
      "Epoch 250/500\n",
      "43/43 [==============================] - 26s 594ms/step - loss: 0.2177 - categorical_accuracy: 0.9414\n",
      "Epoch 251/500\n",
      "43/43 [==============================] - 26s 596ms/step - loss: 0.2024 - categorical_accuracy: 0.9462\n",
      "Epoch 252/500\n",
      "43/43 [==============================] - 26s 599ms/step - loss: 0.2001 - categorical_accuracy: 0.9469\n",
      "Epoch 253/500\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 0.1975 - categorical_accuracy: 0.9490\n",
      "Epoch 254/500\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 0.1927 - categorical_accuracy: 0.9512\n",
      "Accuracy reach over 0.95% terminating train process.\n"
     ]
    }
   ],
   "source": [
    "#categorical_accuracy\n",
    "cb = My_Callback(0.95)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "history = model.fit(X, y, batch_size=4096, epochs=500, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 22s 435ms/step - loss: 0.1404 - categorical_accuracy: 0.9665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15542151033878326, 0.9619872570037842]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.save_weights(\"model/tr-lang-model.h5\")\n",
    "model.load_weights(\"model/tr-lang-model.h5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "model.evaluate(X,y,batch_size = 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "def plot_history(history):\n",
    "    acc = history.history['categorical_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.title('Training  accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'r', label='Training loss')\n",
    "    plt.title('Training loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate sequence basically get seed text and and consider 5 word from right side and ignore others, if its less than 5 padding(pre) from left side after that for each 5 word model predict 1 word. After prediction we feed 4 word from previous input and previously predicted word as 5th word and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dynamic printing\n",
    "from IPython.display import display, clear_output\n",
    "# padding for fixed input size\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# generating sequence from language model\n",
    "def generate_sequence(tokenizer, max_output_seq_len, n_input_words, seed_text, model):\n",
    "    model_input = seed_text\n",
    "    \n",
    "    # generate given max amount of word\n",
    "    for _ in range(max_output_seq_len):\n",
    "        # tokenize input text\n",
    "        model_input_encoded = tokenizer.texts_to_sequences([model_input])[0]\n",
    "        # pre-padding for fixed length(n_input_words)\n",
    "        model_input_encoded = pad_sequences([model_input_encoded], maxlen=n_input_words, padding='pre')\n",
    "        # predict probabilties for each word in vocab.\n",
    "        prediction = model.predict(model_input_encoded)[0]\n",
    "        prediction = np.argmax(prediction)\n",
    "        # finding predicted word\n",
    "        predicted_word = list(tokenizer.word_index.keys())[prediction-1]\n",
    "        model_input = model_input + \" \" + predicted_word\n",
    "        display(model_input)\n",
    "        clear_output(wait=True)\n",
    "    return model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dynamic printing\n",
    "from IPython.display import display, clear_output\n",
    "# padding for fixed input size\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# generating sequence from language model\n",
    "def generate_sequence_with_random_choice(tokenizer, max_output_seq_len, n_input_words, seed_text, model, acceptance_threshold):\n",
    "    model_input = seed_text\n",
    "    \n",
    "    # generate given max amount of word\n",
    "    for _ in range(max_output_seq_len):\n",
    "        # variable countermeasure if threshold too high for prediction\n",
    "        at = acceptance_threshold\n",
    "        # tokenize input text\n",
    "        model_input_encoded = tokenizer.texts_to_sequences([model_input])[0]\n",
    "        # pre-padding for fixed length(n_input_words)\n",
    "        model_input_encoded = pad_sequences([model_input_encoded], maxlen=n_input_words, padding='pre')\n",
    "        # predict probabilties for each word in vocab.\n",
    "        prediction = model.predict(model_input_encoded)\n",
    "        # countermeasure if threshold too high for prediction\n",
    "        if np.max(prediction) < acceptance_threshold:\n",
    "            at = np.max(prediction)\n",
    "        # take predicted words with probability higher than the threshold\n",
    "        prediction = prediction >= at\n",
    "        # taking index high prob. words(true values)\n",
    "        possible_words = np.where(prediction)[1]\n",
    "        # choosing one of possible word\n",
    "        choosen_index = possible_words[np.random.randint(0,len(possible_words))]\n",
    "        # getting correspanding key from word index\n",
    "        predicted_word = list(tokenizer.word_index.keys())[choosen_index-1]\n",
    "        model_input = model_input + \" \" + predicted_word\n",
    "        display(model_input)\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "    return model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ne olursan o ’ hicabıdır , bizim bütün bunlar bizim ilk ne demek ey / maddî yolunda şirk olur ; gönülleri mı varsa var ; yoksa hiç'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sequence(tokenizer, 25, n_word, \"Ne olursan\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ne olursan o kötü bütün âlem ıssı , devletler , senin , hıyanet bize arap bile olması . - kötü şems , merhamet üzere yalnız benim ,'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sequence_with_random_choice(tokenizer, 25, n_word, \"Ne olursan\", model,acceptance_threshold = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sen nasıl rızka düşkün da bu hikâyelerden sahibi , soğuk bir iş , “ durursun . ” hepsi vardır , kuş , nefis iç bir can ! bir de vuslat ayranı yüce muhammed ’ ile selam imdada yetişti . dünyada iki hayırlı ekin , birbirine söz ancak bir varlık var , kuldur de aynı pek büyük ilimden de aynı kur ’ an ’ bir avuç yeter . kitaptan bir işte söyler . bu birisinin şeyler olmazsa yine onu . . . onun , öç alınarak selamlar ve esenlik . size en allah ’ a hamdolsun – hükmünce artık gökyüzü , ayrı az ile bir saray iki kıymetli yarattı ne meydana kalır , onu bir kişiyi verdiği açarlar ; elbette onlar , yüz bin şey üstün devleti göz bin huyları gel . hak teâlâ ’ in lütfudur . fasıl . dost suresi , : . bunların en yüce işlerle kaldı . ey eski er ,'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sequence(tokenizer, 150, n_word, \"Sen nasıl rızka düşkün\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sen nasıl rızka düşkün da bu hikâyelerden sahibi , soğuk bir iş , “ durursun . ” hepsi vardır , kuş , nefis iç bir can ! bir de vuslat ayranı yüce muhammed ’ ile selam imdada yetişti . dünyada iki hayırlı ekin , birbirine söz ancak bir varlık var , kuldur de aynı pek büyük ilimden de aynı kur ’ an ’ bir avuç yeter . kitaptan bir işte söyler . bu birisinin şeyler olmazsa yine onu . . . onun , öç alınarak selamlar ve esenlik . size en allah ’ a hamdolsun – hükmünce artık gökyüzü , ayrı az ile bir saray iki kıymetli yarattı ne meydana kalır , onu bir kişiyi verdiği açarlar ; elbette onlar , yüz bin şey üstün devleti göz bin huyları gel . hak teâlâ ’ in lütfudur . fasıl . dost suresi , : . bunların en yüce işlerle kaldı . ey eski er ,'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sequence_with_random_choice(tokenizer, 150, n_word, \"Sen nasıl rızka düşkün\", model,acceptance_threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sahildeki kafka olan sâhib ’ in durağı olup - kader - i kadar mi penceredeki habib , ayı ayağa , ey gönül celâl ve ey lütuf yaratan . ” , kahır bütün bunlar . şimdi , güzeller sevgilinin geldi ; artık gümüş gibi meydana ve zaman yazı . sihir ’ nuh ehli'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sequence(tokenizer, 50, n_word, \"Sahildeki kafka\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
